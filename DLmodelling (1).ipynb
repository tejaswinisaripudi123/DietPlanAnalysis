{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "DLmodelling.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pyj8ijwWnF7"
      },
      "source": [
        "from keras.models import load_model\n",
        "from keras.preprocessing import image\n",
        "import numpy\n",
        "import cv2"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQ2jHz80inzz"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Convolution2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_Js2WXYiqXZ"
      },
      "source": [
        "model=Sequential()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGu4CQuKitcy"
      },
      "source": [
        "model.add(Convolution2D(32,(3,3),input_shape=(64,64,3)))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tECscu8Uiy14"
      },
      "source": [
        "model.add(MaxPooling2D(pool_size=(2,2)))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnfnG4l-i0eF"
      },
      "source": [
        "model.add(Flatten())"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIqsCXrBi7WK"
      },
      "source": [
        "model.add(Dense(units=128,activation=\"relu\"))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3HBtpkCjNDe"
      },
      "source": [
        "model.add(Dense(units=4,activation=\"softmax\"))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIpH9yNhjQnr"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6gmHNS4jUWr"
      },
      "source": [
        "train_datagen=ImageDataGenerator(rescale=1./255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41DOFJF1WnF_",
        "outputId": "4430520b-fa6c-4b24-da4a-1244da488a70"
      },
      "source": [
        "x_train=train_datagen.flow_from_directory(r'/content/drive/MyDrive/testing/trainset',target_size=(64,64),batch_size=32,class_mode=\"categorical\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 279 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGlc8Y2XI4vd",
        "outputId": "d71c12f8-02d5-4b45-cad1-3a88f0fd7fe9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(x_train.class_indices)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'apple': 0, 'banana': 1, 'mango': 2, 'orange': 3}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUllrDCsI6NH"
      },
      "source": [
        "test_datagen=ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eo90XPb7JmWs",
        "outputId": "4d07a315-1d42-4be4-8510-915df8f624eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x_test=test_datagen.flow_from_directory(r'/content/drive/MyDrive/testing/testset',target_size=(64,64),batch_size=32,class_mode=\"categorical\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 7 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUY70cuCI98c",
        "outputId": "cfa15e31-b0af-4d69-df72-ae2d379c1adf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "model.fit_generator(x_train,steps_per_epoch=9,epochs=31,validation_data=x_test,validation_steps=4)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/31\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 69s 4s/step - loss: 6.2280 - accuracy: 0.2186\n",
            "Epoch 2/31\n",
            "9/9 [==============================] - 2s 247ms/step - loss: 1.9194 - accuracy: 0.3763\n",
            "Epoch 3/31\n",
            "9/9 [==============================] - 2s 250ms/step - loss: 1.0709 - accuracy: 0.5233\n",
            "Epoch 4/31\n",
            "9/9 [==============================] - 2s 254ms/step - loss: 0.8570 - accuracy: 0.6237\n",
            "Epoch 5/31\n",
            "9/9 [==============================] - 2s 258ms/step - loss: 0.7309 - accuracy: 0.7276\n",
            "Epoch 6/31\n",
            "9/9 [==============================] - 2s 264ms/step - loss: 0.6567 - accuracy: 0.7348\n",
            "Epoch 7/31\n",
            "9/9 [==============================] - 2s 249ms/step - loss: 0.6316 - accuracy: 0.7455\n",
            "Epoch 8/31\n",
            "9/9 [==============================] - 2s 252ms/step - loss: 0.5767 - accuracy: 0.7885\n",
            "Epoch 9/31\n",
            "9/9 [==============================] - 2s 263ms/step - loss: 0.5744 - accuracy: 0.7384\n",
            "Epoch 10/31\n",
            "9/9 [==============================] - 2s 267ms/step - loss: 0.5446 - accuracy: 0.7778\n",
            "Epoch 11/31\n",
            "9/9 [==============================] - 2s 275ms/step - loss: 0.5137 - accuracy: 0.8029\n",
            "Epoch 12/31\n",
            "9/9 [==============================] - 2s 269ms/step - loss: 0.5198 - accuracy: 0.7921\n",
            "Epoch 13/31\n",
            "9/9 [==============================] - 2s 273ms/step - loss: 0.5049 - accuracy: 0.7814\n",
            "Epoch 14/31\n",
            "9/9 [==============================] - 2s 261ms/step - loss: 0.4669 - accuracy: 0.8065\n",
            "Epoch 15/31\n",
            "9/9 [==============================] - 2s 271ms/step - loss: 0.4319 - accuracy: 0.8423\n",
            "Epoch 16/31\n",
            "9/9 [==============================] - 2s 260ms/step - loss: 0.4104 - accuracy: 0.8280\n",
            "Epoch 17/31\n",
            "9/9 [==============================] - 2s 268ms/step - loss: 0.4114 - accuracy: 0.8208\n",
            "Epoch 18/31\n",
            "9/9 [==============================] - 3s 280ms/step - loss: 0.3937 - accuracy: 0.8315\n",
            "Epoch 19/31\n",
            "9/9 [==============================] - 2s 254ms/step - loss: 0.3451 - accuracy: 0.8638\n",
            "Epoch 20/31\n",
            "9/9 [==============================] - 2s 276ms/step - loss: 0.3047 - accuracy: 0.8996\n",
            "Epoch 21/31\n",
            "9/9 [==============================] - 2s 269ms/step - loss: 0.3069 - accuracy: 0.9176\n",
            "Epoch 22/31\n",
            "9/9 [==============================] - 2s 250ms/step - loss: 0.2873 - accuracy: 0.9104\n",
            "Epoch 23/31\n",
            "9/9 [==============================] - 2s 258ms/step - loss: 0.3196 - accuracy: 0.8925\n",
            "Epoch 24/31\n",
            "9/9 [==============================] - 2s 262ms/step - loss: 0.2997 - accuracy: 0.9176\n",
            "Epoch 25/31\n",
            "9/9 [==============================] - 2s 262ms/step - loss: 0.2987 - accuracy: 0.8925\n",
            "Epoch 26/31\n",
            "9/9 [==============================] - 2s 256ms/step - loss: 0.2940 - accuracy: 0.8889\n",
            "Epoch 27/31\n",
            "9/9 [==============================] - 2s 262ms/step - loss: 0.2369 - accuracy: 0.9391\n",
            "Epoch 28/31\n",
            "9/9 [==============================] - 2s 261ms/step - loss: 0.2467 - accuracy: 0.9319\n",
            "Epoch 29/31\n",
            "9/9 [==============================] - 2s 246ms/step - loss: 0.2292 - accuracy: 0.9355\n",
            "Epoch 30/31\n",
            "9/9 [==============================] - 2s 264ms/step - loss: 0.1842 - accuracy: 0.9498\n",
            "Epoch 31/31\n",
            "9/9 [==============================] - 2s 261ms/step - loss: 0.2062 - accuracy: 0.9247\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f172b21acd0>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJfywbFmCfTO",
        "outputId": "101e937f-1c26-4ea0-eea9-ce929dbff776"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOA-3Tzmtt30"
      },
      "source": [
        "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Zq46fQaIuaV",
        "outputId": "5c241f57-27ec-4b95-8572-f07b5b094b34",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "model.fit_generator(x_train,steps_per_epoch=9,epochs=31,validation_data=x_test,validation_steps=4)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/31\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.1821 - accuracy: 0.9355WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 4 batches). You may need to use the repeat() function when building your dataset.\n",
            "9/9 [==============================] - 8s 960ms/step - loss: 0.1821 - accuracy: 0.9355 - val_loss: 5.5586 - val_accuracy: 0.5714\n",
            "Epoch 2/31\n",
            "9/9 [==============================] - 2s 254ms/step - loss: 0.1737 - accuracy: 0.9498\n",
            "Epoch 3/31\n",
            "9/9 [==============================] - 2s 258ms/step - loss: 0.1858 - accuracy: 0.9355\n",
            "Epoch 4/31\n",
            "9/9 [==============================] - 2s 265ms/step - loss: 0.1571 - accuracy: 0.9606\n",
            "Epoch 5/31\n",
            "9/9 [==============================] - 2s 268ms/step - loss: 0.1546 - accuracy: 0.9642\n",
            "Epoch 6/31\n",
            "9/9 [==============================] - 2s 260ms/step - loss: 0.1267 - accuracy: 0.9749\n",
            "Epoch 7/31\n",
            "9/9 [==============================] - 2s 256ms/step - loss: 0.1615 - accuracy: 0.9570\n",
            "Epoch 8/31\n",
            "9/9 [==============================] - 2s 263ms/step - loss: 0.1473 - accuracy: 0.9498\n",
            "Epoch 9/31\n",
            "9/9 [==============================] - 2s 263ms/step - loss: 0.1445 - accuracy: 0.9713\n",
            "Epoch 10/31\n",
            "9/9 [==============================] - 2s 259ms/step - loss: 0.1199 - accuracy: 0.9785\n",
            "Epoch 11/31\n",
            "9/9 [==============================] - 2s 244ms/step - loss: 0.1174 - accuracy: 0.9642\n",
            "Epoch 12/31\n",
            "9/9 [==============================] - 2s 254ms/step - loss: 0.1107 - accuracy: 0.9677\n",
            "Epoch 13/31\n",
            "9/9 [==============================] - 2s 271ms/step - loss: 0.0829 - accuracy: 0.9821\n",
            "Epoch 14/31\n",
            "9/9 [==============================] - 2s 260ms/step - loss: 0.0878 - accuracy: 0.9821\n",
            "Epoch 15/31\n",
            "9/9 [==============================] - 2s 241ms/step - loss: 0.1207 - accuracy: 0.9606\n",
            "Epoch 16/31\n",
            "9/9 [==============================] - 2s 271ms/step - loss: 0.0853 - accuracy: 0.9821\n",
            "Epoch 17/31\n",
            "9/9 [==============================] - 2s 267ms/step - loss: 0.1052 - accuracy: 0.9642\n",
            "Epoch 18/31\n",
            "9/9 [==============================] - 2s 261ms/step - loss: 0.0780 - accuracy: 0.9821\n",
            "Epoch 19/31\n",
            "9/9 [==============================] - 2s 278ms/step - loss: 0.0738 - accuracy: 0.9821\n",
            "Epoch 20/31\n",
            "9/9 [==============================] - 2s 263ms/step - loss: 0.0743 - accuracy: 0.9785\n",
            "Epoch 21/31\n",
            "9/9 [==============================] - 2s 269ms/step - loss: 0.0648 - accuracy: 0.9928\n",
            "Epoch 22/31\n",
            "9/9 [==============================] - 2s 260ms/step - loss: 0.0669 - accuracy: 0.9857\n",
            "Epoch 23/31\n",
            "9/9 [==============================] - 2s 266ms/step - loss: 0.0750 - accuracy: 0.9749\n",
            "Epoch 24/31\n",
            "9/9 [==============================] - 2s 257ms/step - loss: 0.0619 - accuracy: 0.9892\n",
            "Epoch 25/31\n",
            "9/9 [==============================] - 2s 270ms/step - loss: 0.0585 - accuracy: 0.9821\n",
            "Epoch 26/31\n",
            "9/9 [==============================] - 2s 257ms/step - loss: 0.0838 - accuracy: 0.9785\n",
            "Epoch 27/31\n",
            "9/9 [==============================] - 2s 279ms/step - loss: 0.0789 - accuracy: 0.9785\n",
            "Epoch 28/31\n",
            "9/9 [==============================] - 2s 245ms/step - loss: 0.0862 - accuracy: 0.9749\n",
            "Epoch 29/31\n",
            "9/9 [==============================] - 2s 259ms/step - loss: 0.0789 - accuracy: 0.9749\n",
            "Epoch 30/31\n",
            "9/9 [==============================] - 2s 250ms/step - loss: 0.0506 - accuracy: 0.9928\n",
            "Epoch 31/31\n",
            "9/9 [==============================] - 2s 260ms/step - loss: 0.0605 - accuracy: 0.9857\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f172a9bf110>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxpR9amZWnF_",
        "outputId": "5cde2bd5-f175-4c94-9937-202114609d11"
      },
      "source": [
        "#pred=model.predict_classes(x)\n",
        "#pred\n",
        "import numpy as np\n",
        "np.argmax(model.predict(x_train), axis=-1)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 3, 3, 3, 3, 3, 2, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3,\n",
              "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 2, 3, 3, 3,\n",
              "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "       3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "       3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3,\n",
              "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "       3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "       3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3,\n",
              "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jyA0Oy8WnGA"
      },
      "source": [
        "img=image.load_img('orange_95.jpg',target_size=(64,64))\n",
        "x=image.img_to_array(img)\n",
        "x=numpy.expand_dims(x,axis=0)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxYSr9gLWnGA",
        "outputId": "9cdbc6ca-1240-4ef8-f224-1aac71b2782b"
      },
      "source": [
        "predictions=numpy.argmax(model.predict(x_train), axis=-1)\n",
        "if(predictions[0]==0):\n",
        "    print(\"apple\")\n",
        "elif(predictions[0]==1):\n",
        "    print(\"banana\")\n",
        "elif(predictions[0]==2):\n",
        "    print(\"mango\")\n",
        "else:\n",
        "    print(\"oranges\")"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "oranges\n"
          ]
        }
      ]
    }
  ]
}